{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (LU3IN0226) -- 2022-2023\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Christophe Marsala, Olivier Schwander, Jean-Noël Vittaut.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\"><b>[Q]</b></font> <font size=\"+1\"><b>Indiquer dans la boîte ci-dessous vos noms et prénoms :</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Double-cliquer ici et insérer les noms et prénoms de votre binôme*\n",
    ">**Saliou Barry <br>\n",
    "Timo Brisset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce projet peut être fait en binôme (et c'est fortement conseillé) ou tout seul.\n",
    "\n",
    "Le nom de chaque membre du binôme doit être indiqué, et un seul rendu sur un des deux comptes Moodle doit être fait.\n",
    "\n",
    "Les groupes de plus de 2 personnes ne sont pas autorisés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\"><b>[Q]</b></font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>projet-2</tt> et rajouter à la suite de <tt>projet-2</tt> les noms des membres du binômes séparés par un tiret.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au notebook** : *projet-2-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "\n",
    "**Le compte-rendu doit être rendu sur la page Moodle.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet 2 - avril-mai 2023\n",
    "\n",
    "\n",
    "<font size=\"+1\" color=\"RED\"><b>Date de rendu : lundi 22 mai 2023, avant 18h</b></font>\n",
    "    \n",
    "<b>Attention! le site Moodle ferme à 18h pile !</b> prévoyez de vous y connecter au moins 15mn avant la fermeture...\n",
    "\n",
    "Vous devez compléter ce notebook en rajoutant vos expérimentations avec vos algorithmes d'apprentissage sur les données fournies dans le répertoire `data`.\n",
    "\n",
    "## Travail à faire\n",
    "\n",
    "Appliquer les algorithmes d'apprentissage vus tout au long du semestre sur les données afin de mettre en évidence des résultats intéressants.\n",
    "Deux problèmes, au moins, doivent être traités:\n",
    "- un problème d'apprentissage supervisé\n",
    "- un problème d'apprentissage non supervisé\n",
    "\n",
    "\n",
    "## Travail à rendre\n",
    "Ce qui doit être remis avant la date limite : un fichier archive (`.tar`, `.tgz`, ou `.zip` uniquement) contenant:\n",
    "- ce notebook complété. Il doit pouvoir être exécuté sans autre apport (pensez à vous en assurer avant de le rendre). \n",
    "- votre librairie iads sous la forme d'une archive avec votre répertoire `iads/` contenant tous les fichiers nécessaires \n",
    "- un fichier PDF dont le nom est de la forme: *projet-1-Nom1_Nom2.pdf* qui correspond à un poster décrivant l'ensemble des expérimentations menées et les résultats obtenus.\n",
    "\n",
    "\n",
    "<b>IMPORTANT</b>: \n",
    "- Les fichiers de données ne doivent pas être inclus dans votre archive ! \n",
    "- Pensez à vérifier que votre archive contient bien tous les fichiers demandés et QUE les fichiers demandés.\n",
    "\n",
    "## Soutenance des projets\n",
    "La soutenance aura lieu le <font size=\"+1\" color=\"RED\">**mercredi 24 mai 2023**</font>, à partir de 14h. Un ordre de passage ainsi que la salle de TME où aura lieu les soutenances seront affichées sur le Moodle la veille.\n",
    "\n",
    "La <b>soutenance est obligatoire</b> : tout projet pour lequel une soutenance n'a pas eu lieu sera noté $0$.\n",
    "\n",
    "Modalités de la soutenance:\n",
    "- durée de la soutenance : 10 mn pour un binôme, 7 mn pour un monôme ;\n",
    "- elle a lieu devant un ordinateur avec le notebook et le poster comme support ;\n",
    "    - elle commence par une rapide présentation des expérimentations réalisées et résultats obtenus (max. 4 à 5mns)\n",
    "    - puis elle se poursuit par des questions posées individuellement aux membres du binômes sur les expériences ou le code python réalisé.\n",
    "- la note de soutenance est individuelle pour chaque membre d'un binôme.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Très important** : les fichiers de données doivent être placés de façon à respecter la structure de fichiers suivante :\n",
    "\n",
    "          --iads/\n",
    "              -- Classifiers.py\n",
    "              -- etc.\n",
    "          -- projet/\n",
    "              -- ce_notebook.ipynb\n",
    "              -- data/\n",
    "                  -- AGRIBALYSE3-ingredients.csv\n",
    "                  -- AGRIBALYSE3-etapes.csv\n",
    "                  -- AGRIBALYSE3-synthese.csv\n",
    "\n",
    "\n",
    "Dans le notebook que vous rendrez, le chargement des fichiers de données considèrera donc cette arborescence.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les données Agribalyse (version 3.1)\n",
    "\n",
    "Les données sont issues des données publiques du site de l'ADEME: https://agribalyse.ademe.fr/\n",
    "Il est conseillé de parcourir la documentation de ces données sur le site ci-dessus pour se familiariser avec les différentes informations qu'elles fournissent.\n",
    "\n",
    "Pour ce projet, vous travaillerez sur les données sur les produits alimentaires dont la version originale est visible ici : https://doc.agribalyse.fr/documentation/acces-donnees\n",
    "\n",
    "Si vous n'arrivez pas à télécharger ou à ouvrir ce fichier, des versions de ce fichier au format libreoffice et au format Excel 97 sont fournies dans l'archive `data_tableur`. Il est conseillé de regarder un de ces fichiers car vous y trouverez des informations complémentaires sur les noms des colonnes des 3 fichiers CSV de `data` décrits ci-dessous.\n",
    "\n",
    "Pour vous aider à manipuler les données nous vous fournissons dans l'archive `data` : les 3 tables du fichiers sont fournies sous la forme de 3 fichiers CSV directement lisibles par la commande `read_csv` de Pandas (le séparateur de colonnes est le `';'`). Ce sont ces 3 fichiers à utiliser dans votre notebook. Un exemple de chargement est donné plus loin dans ce notebook. Les fichiers sont:\n",
    "- AGRIBALYSE3-ingredients.csv\n",
    "- AGRIBALYSE3-etapes.csv\n",
    "- AGRIBALYSE3-synthese.csv\n",
    "\n",
    "**Remarque**: les données Agribalyse de 2021 ont fait l'objet du projet de l'an dernier, cette année c'est une nouvelle version étendue de ces données qui sont utilisées pour ce projet, nous attendons donc des analyses qui tirent partie des nouveautés de cette nouvelle version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies standards:\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# Importation de votre librairie iads:\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')   # iads doit être dans le répertoire frère du répertoire courant !\n",
    "\n",
    "# Importation de la librairie seaborn:\n",
    "import seaborn as sns\n",
    "\n",
    "# Importation de la librairie iads\n",
    "import iads as iads\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n",
    "\n",
    "# importation de evaluation\n",
    "from iads import evaluation as ev\n",
    "\n",
    "# importation de Clustering\n",
    "from iads import Clustering as clust\n",
    "\n",
    "import graphviz as gv\n",
    "\n",
    "# commande TRES utile pour recharger automatiquement le code que vous modifiez dans les modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_synthese = pd.read_csv(\"data/AGRIBALYSE3-synthese.csv\", sep=';') \n",
    "data_synthese.columns\n",
    "print(\"Nombre de lignes: \",len(data_synthese))\n",
    "print(\"Nombre de colonnes: \",len(data_synthese.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data_synthese.columns)):\n",
    "    if i>10:\n",
    "        #print(\"col \",i,\": \",data_synthese.columns[i], \"\\tmoyenne = \",data_synthese[data_synthese.columns[i]].mean())\n",
    "    else:\n",
    "        #print(\"col \",i,\": \",data_synthese.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_etapes = pd.read_csv(\"data/AGRIBALYSE3-etapes.csv\", sep=';') \n",
    "data_etapes.columns\n",
    "print(\"Nombre de lignes: \",len(data_etapes))\n",
    "print(\"Nombre de colonnes: \",len(data_etapes.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data_etapes.columns)):\n",
    "    pass\n",
    "    #print(\"col \",i,\": \",data_etapes.columns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Quelques infos :\")\n",
    "for i in range(0,17):\n",
    "    #print(\"----\")\n",
    "    for col in ['Agriculture', 'Transformation', 'Emballage', 'Transport', 'Supermarché et distribution', \\\n",
    "                'Consommation', 'Total']:\n",
    "        if i>0:\n",
    "            nom_col = col + \".\" +str(i)\n",
    "        else:\n",
    "            nom_col = col\n",
    "        #print(nom_col,\"\\tmoyenne = \",data_etapes[nom_col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ingredients = pd.read_csv(\"data/AGRIBALYSE3-ingredients.csv\",sep=\";\")\n",
    "data_ingredients.columns\n",
    "print(\"Nombre de lignes: \",len(data_ingredients))\n",
    "print(\"Nombre de colonnes: \",len(data_ingredients.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(data_ingredients.columns)):\n",
    "    if i<10:\n",
    "        print(i,\": \", data_ingredients.columns[i])\n",
    "    else:\n",
    "        print(i,\": \", data_ingredients.columns[i], \\\n",
    "              \"\\tmoyennne = \", data_ingredients[data_ingredients.columns[i]].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data_synthese.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etude 1 : Changement Climatique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbre de décision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tt>Nous avons utilisé l'algorithme de l'arbre de décision pour prédire l'impact sur l'environnement des différents sous-groupes d'aliments **(Changement Climatique)**. En utilisant les données relatives à `l'agriculture, la transformation, l'emballage, le transport, la distribution et la consommation de ces aliments `, nous avons entraîné un modèle d'arbre de décision qui est capable de prendre des décisions basées sur les caractéristiques environnementales des produits. En utilisant cet algorithme, nous avons pu prédire la catégorie d'impact environnemental (faible, modéré, fort, très fort) pour chaque sous-groupe d'aliments. Cette approche nous a permis d'obtenir des informations utiles sur l'impact environnemental des différentes étapes de production et de consommation alimentaires.</tt>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation des données\n",
    "\n",
    "#### Définir les seuils de classification\n",
    "Nous commençons par définir les seuils de classification pour l'impact climatique. Ces seuils nous permettront de catégoriser les données en fonction de leur niveau d'impact. Dans notre exemple, nous avons défini les seuils suivants :\n",
    "- Seuil faible : 10\n",
    "- Seuil modéré : 20\n",
    "- Seuil fort : 30\n",
    "\n",
    "#### Créer une nouvelle colonne d'étiquettes\n",
    "Pour pouvoir attribuer une étiquette de classe à chaque donnée, nous créons une nouvelle colonne appelée \"classe\" dans le dataframe \"data_synthese\". Cette colonne sera utilisée pour stocker les étiquettes correspondantes à chaque donnée.\n",
    "\n",
    "#### Assigner les étiquettes en fonction des seuils\n",
    "Nous attribuons maintenant les étiquettes de classe en fonction des seuils de classification que nous avons définis. À l'aide de la méthode \"loc\" de pandas, nous sélectionnons les lignes du dataframe \"data_synthese\" qui satisfont les conditions spécifiées et attribuons les étiquettes correspondantes à la colonne \"classe\". Par exemple, si la valeur de la colonne \"Changement climatique\" est inférieure au seuil faible, nous assignons l'étiquette \"faible impact\". De même, nous assignons les étiquettes \"impact modéré\", \"fort impact\" et \"très fort impact\" en fonction des autres seuils.\n",
    "\n",
    "#### Extraction de la colonne des étiquettes de classe\n",
    "Nous extrayons maintenant la colonne des étiquettes de classe (\"classe\") à partir du dataframe \"data_synthese\" et la stockons dans la variable \"etiquettes_classe\". Cette colonne sera utilisée ultérieurement pour l'analyse des données.\n",
    "\n",
    "#### Sélection des colonnes nécessaires pour former le dataframe \"donnees_alimentaires\"\n",
    "Nous sélectionnons les colonnes pertinentes du dataframe \"data_etapes\" qui seront utilisées pour former le dataframe \"donnees_alimentaires\". Ces colonnes comprennent les informations sur le sous-groupe d'aliment ainsi que les différentes étapes de production et de distribution.\n",
    "\n",
    "#### Concaténation du dataframe \"donnees_alimentaires\" avec la colonne \"classe_df\"\n",
    "Enfin, nous concaténons le dataframe \"donnees_alimentaires\" avec la colonne \"classe_df\" du dataframe \"data_synthese\". Cela nous permet de regrouper les informations sur les aliments avec leurs étiquettes de classe correspondantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définir les seuils de classification\n",
    "seuil_faible = 10\n",
    "seuil_modere = 20\n",
    "seuil_fort = 30\n",
    "\n",
    "# Créer une nouvelle colonne d'étiquettes\n",
    "data_synthese['classe'] = ''\n",
    "\n",
    "# Assigner les étiquettes en fonction des seuils\n",
    "data_synthese.loc[data_synthese['Changement climatique'] < seuil_faible, 'classe'] = 'faible impact'\n",
    "data_synthese.loc[(data_synthese['Changement climatique'] >= seuil_faible) & (data_synthese['Changement climatique'] < seuil_modere), 'classe'] = 'impact modéré'\n",
    "data_synthese.loc[(data_synthese['Changement climatique'] >= seuil_modere) & (data_synthese['Changement climatique'] < seuil_fort), 'classe'] = 'fort impact'\n",
    "data_synthese.loc[data_synthese['Changement climatique'] >= seuil_fort, 'classe'] = 'très fort impact'\n",
    "\n",
    "# Extraction de la colonne des étiquettes de classe à partir du dataframe \"data_synthese\"\n",
    "etiquettes_classe = data_synthese[\"classe\"]\n",
    "\n",
    "# Sélection des colonnes nécessaires du dataframe \"data_etapes\" pour former le dataframe \"donnees_alimentaires\"\n",
    "donnees_alimentaires = data_etapes[[\"Sous-groupe d aliment\",\"Agriculture.1\",\"Transformation.1\",\"Emballage.1\",\"Transport.1\",\"Supermarché et distribution.1\", \"Consommation.1\"]]\n",
    "\n",
    "# Concaténation du dataframe \"donnees_alimentaires\" avec la colonne \"classe_df\" du dataframe \"data_synthese\"\n",
    "donnees_alimentaires = pd.concat([donnees_alimentaires, etiquettes_classe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Avec Seaborn, on peut construire le corrélogramme de ce dataset:\n",
    "sns.pairplot(donnees_alimentaires.iloc[:,1:],hue='classe',palette='bright')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "donnees_alimentaires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base d'apprentissage et test\n",
    "Nous avons choisi d'extraire les données par sous-groupe pour créer des ensembles de test distincts afin de garantir une distribution équilibrée, d'évaluer les performances spécifiques à chaque catégorie d'aliments, de prendre en compte les variations des caractéristiques et de favoriser la généralisation du modèle. Cette approche nous permet d'obtenir une évaluation juste, précise et représentative de notre modèle, tout en tenant compte des particularités de chaque sous-groupe, ce qui est essentiel pour des prédictions fiables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupement des données du dataframe donnees_alimentaires selon la colonne \"Sous-groupe d'aliment\"\n",
    "grouped = donnees_alimentaires.groupby(\"Sous-groupe d aliment\")\n",
    "\n",
    "# Séparation des données en ensembles d'apprentissage et de test par validation croisée stratifiée\n",
    "train_desc, label_train = [], []\n",
    "test_desc, label_test = [], []\n",
    "\n",
    "# Boucle sur les groupes créés à partir de la colonne \"Sous-groupe d aliment\" du dataframe x\n",
    "for _, group_df in grouped:\n",
    "    # Extraction des données et des étiquettes pour le groupe courant\n",
    "    data = np.array(group_df[[\"Agriculture.1\", \"Transformation.1\", \"Emballage.1\", \"Transport.1\", \"Supermarché et distribution.1\", \"Consommation.1\"]])\n",
    "    label = np.array(group_df[\"classe\"])\n",
    "    \n",
    "    # Mélange aléatoire des index\n",
    "    index = np.random.permutation(len(label))\n",
    "    data = data[index]\n",
    "    label = label[index]\n",
    "    \n",
    "    # Séparation des données en ensembles d'apprentissage et de test par validation croisée stratifiée\n",
    "    Xapp, Yapp, Xtest, Ytest = ut.crossval_strat(data, label, 3, 0)\n",
    "    \n",
    "    # Ajout des données et des étiquettes aux ensembles d'apprentissage et de test\n",
    "    train_desc.append(Xapp)\n",
    "    label_train.append(Yapp)\n",
    "    test_desc.append(Xtest)\n",
    "    label_test.append(Ytest)\n",
    "\n",
    "# Concaténation des ensembles d'apprentissage et de test\n",
    "train_desc = np.concatenate(train_desc, axis=0)\n",
    "label_train = np.concatenate(label_train, axis=0)\n",
    "test_desc = np.concatenate(test_desc, axis=0)\n",
    "label_test = np.concatenate(label_test, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Récupération des noms de colonnes du dataframe \"donnees_alimentaires\"\n",
    "noms = donnees_alimentaires.columns[1:]\n",
    "\n",
    "# Initialisation de l'arbre de décision en utilisant la classe ClassifierArbreNumerique\n",
    "arbre_decision = cl.ClassifierArbreNumerique(len(np.array(noms)), 0.0, np.array(noms))\n",
    "\n",
    "# Entraînement de l'arbre de décision sur les données d'entraînement\n",
    "arbre_decision.train(train_desc, label_train)\n",
    "\n",
    "# Construction de la représentation graphique de l'arbre de décision (affichage)\n",
    "graphe_arbre = gv.Digraph(format='png')\n",
    "arbre_decision.affiche(graphe_arbre)\n",
    "\n",
    "# Affichage du graphe de l'arbre de décision\n",
    "graphe_arbre \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'exactitude du modèle d'arbre de décision\n",
    "acc = arbre_decision.accuracy(test_desc, label_test)\n",
    "\n",
    "# Affichage de l'exactitude\n",
    "print(\"Accuracy:  {}\".format(acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# ETUDE 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix du Problématique\n",
    "Nous avons choisi d'aborder la problématique de l'écotoxicité pour les écosystèmes aquatiques d'eau douce. Notre objectif était d'évaluer l'impact environnemental des différents sous-groupes d'aliments sur ces écosystèmes en se concentrant sur les étapes de production et de distribution des aliments.\n",
    "\n",
    "Pour réaliser l'étude sur l'écotoxicité pour les écosystèmes aquatiques d'eau douce, nous avons suivi une démarche méthodique, qui est la suivante :\n",
    "\n",
    "**Sélection des colonnes nécessaires :** Nous avons commencé par sélectionner les colonnes pertinentes du dataframe \"data_etapes\" afin de former le dataframe \"donnees_alimentaires\". Les colonnes choisies incluent des informations telles que le code AGB, le groupe d'aliment, le sous-groupe d'aliment et diverses étapes de production, de distribution et de consommation.\n",
    "\n",
    "**Nettoyage des données :** Nous avons supprimé les doublons dans le dataframe \"donnees_alimentaires\" en utilisant la colonne \"Code AGB\" comme critère.\n",
    "\n",
    "**Normalisation des données :** Nous avons effectué la normalisation des données en utilisant la fonction de normalisation fournie dans iads. Nous avons utilisé les colonnes pertinentes du dataframe \"donnees_alimentaires\" pour cette étude, à partir de la colonne 3 jusqu'à la fin.\n",
    "\n",
    "**Application de l'algorithme des K-moyennes :** Nous avons utilisé l'algorithme des K-moyennes dans notre étude pour regrouper les sous-groupes d'aliments en clusters en fonction de leur niveau d'écotoxicité pour les écosystèmes aquatiques d'eau douce. Nous avons choisi de former 3 clusters pour cette étude spécifique. L'algorithme a été exécuté avec une tolérance de convergence de 0.0 et un nombre maximum d'itérations fixé à 100. Les centres et l'affectation de chaque point de données ont été stockés respectivement dans les variables \"centres\" et \"affectation\".\n",
    "\n",
    "**Évaluation des résultats :** Pour évaluer les résultats, nous avons utilisé l'indice de Dunn en utilisant l'indice de dunn, Cet indice nous a fourni une mesure de la séparation et de la compacité des clusters formés.\n",
    "\n",
    "**Analyse des clusters :** À partir des résultats obtenus, nous avons extrait les données des clusters à l'aide de la fonction \"df_clusters\". Cette fonction a renvoyé un ensemble de dataframes correspondant à chaque cluster, ainsi que des informations supplémentaires telles que les labels des clusters et les valeurs moyennes pour une colonne spécifique (\"Total.14\" dans ce cas).\n",
    "\n",
    "**Visualisation des résultats :** Nous avons procédé à la visualisation des résultats en utilisant notre fonction \"plt_pie\" pour représenter la répartition des clusters en fonction de l'écotoxicité des écosystèmes aquatiques d'eau douce. Nous avons également utilisé la fonction \"plot_pie_chart\" pour représenter la composition des aliments dans le cluster présentant la plus grande écotoxicité.\n",
    "\n",
    "En utilisant cette approche, nous avons pu examiner les données des sous-groupes d'aliments et évaluer leur impact sur l'écotoxicité des écosystèmes aquatiques d'eau douce. Cela nous permettra de mieux comprendre la composition de chaque cluster et d'identifier les aliments ayant un impact environnemental plus élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélection des colonnes nécessaires du dataframe \"data_etapes\" pour former le dataframe \"donnees_alimentaires\"\n",
    "data_alimentaires = data_etapes[[\"Code AGB\",\"Groupe d aliment\",\"Sous-groupe d aliment\",\"Agriculture.14\",\"Transformation.14\",\"Emballage.14\",\"Transport.14\",\"Supermarché et distribution.14\", \"Consommation.14\",\"Total.14\"]]\n",
    "\n",
    "# Suppression des doublons basés sur la colonne \"Code AGB\"\n",
    "data_alimentaires = data_alimentaires.drop_duplicates(subset=[\"Code AGB\"])\n",
    "\n",
    "# Réinitialisation de l'index du dataframe pour assurer une indexation continue\n",
    "data_alimentaires = data_alimentaires.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_alimentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Normalisation du dataframe \"data_alimentaires\"\n",
    "df_alimentaires_norm = clust.normalisation(data_alimentaires.iloc[:,3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_alimentaires_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calcul des centres et affectations des données aux clusters en utilisant l'algorithme des k-moyennes\n",
    "centres, affectation = clust.kmoyennes(3, df_alimentaires_norm[[\"Agriculture.14\",\"Total.14\"]],0.0,100)\n",
    "\n",
    "# Calcul de l'indice de Dunn pour évaluer la qualité de la partition en clusters\n",
    "dunn_index = clust.dunn_index(df_alimentaires_norm[[\"Agriculture.14\",\"Total.14\"]], centres, affectation)\n",
    "print(\"Indice de Dunn:\", dunn_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour regrouper les données par cluster\n",
    "\n",
    "def df_clusters(df, affectation, colonne):\n",
    "    ens_df = []  # Liste pour stocker les dataframes de chaque cluster\n",
    "    labels = []  # Liste pour stocker les labels de chaque cluster\n",
    "    valeurs = []  # Liste pour stocker les valeurs moyennes de chaque cluster\n",
    "    moyMax, moyMin = float(\"-inf\"), float(\"inf\")  # Variables pour stocker les valeurs maximales et minimales\n",
    "    indMax, indMin = 0, 0  # Variables pour stocker les indices des clusters, qui ont respectivement le taux \n",
    "                           # d'écotoxicité le plus élevé et le moins élevé\n",
    "\n",
    "    for key in affectation.keys(): \n",
    "        # Récupération du dataframe correspondant au cluster actuel et ajout à la liste\n",
    "        ens_df.append(df.iloc[affectation[key]])\n",
    "\n",
    "        # Calcul de la valeur moyenne de la colonne spécifiée pour le cluster actuel\n",
    "        tmp = ens_df[key][colonne].mean()\n",
    "\n",
    "        label = \"cluster\" + str(key)  # Création du label pour le cluster actuel\n",
    "        labels.append(label)  # Ajout du label à la liste\n",
    "\n",
    "        valeurs.append(tmp)  # Ajout de la valeur moyenne à la liste\n",
    "\n",
    "        if tmp > moyMax: \n",
    "            moyMax = tmp  \n",
    "            indMax = key  \n",
    "        if tmp < moyMin: \n",
    "            moyMin = tmp  \n",
    "            indMin = key  \n",
    "\n",
    "    return ens_df, labels, valeurs, indMax, indMin\n",
    "\n",
    "def plot_pie_chart(dataframe,cluster_index ,col):\n",
    "    \n",
    "    \"\"\"\n",
    "    cette fonction prend en paramètre un dataframe, l'indice du cluster et une colonne, \n",
    "    et génère un graphique en camembert pour représenter les aliments qui composent ce cluster.\n",
    "    \"\"\"\n",
    "    \n",
    "    labels_clust = dataframe.index.tolist()\n",
    "    valeurs_clust = dataframe[col].tolist()\n",
    "\n",
    "    # Création du graphique en camembert\n",
    "    plt.pie(valeurs_clust, labels=labels_clust, autopct='%1.1f%%')\n",
    "\n",
    "    # Titre du graphique\n",
    "    plt.title(\"Les aliments qui composent le Cluster \" + str(cluster_index))\n",
    "\n",
    "    # Affichage du graphique\n",
    "    plt.show()\n",
    "    \n",
    "# Fonction pour afficher un graphique en camembert\n",
    "def plt_pie(title, valeurs, labels) : \n",
    "    # Création du graphique en camembert\n",
    "    plt.pie(valeurs, labels=labels, autopct='%1.1f%%')\n",
    "\n",
    "    # Titre du graphique\n",
    "    plt.title(title)\n",
    "\n",
    "    # Affichage du graphique\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_df, labels, valeurs, indMax, indMin = df_clusters(data_alimentaires, \"Total.14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Affichage du graphique en camembert pour la répartition des clusters en fonction de l'écotoxicité\n",
    "plt_pie(\"Répartition des clusters en fonction de l'écotoxicité pour les écosystèmes aquatiques d'eau douce\", valeurs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clust.affiche_resultat(df_alimentaires_norm, centres, affectation) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regroupement des données par sous-groupe d'aliment et calcul des moyennes :\n",
    "Nous regroupons les dataframes des clusters ayant les valeurs maximales (clustMax) et minimales (clustMin) par \"Sous-groupe d'aliment\" et calculons les moyennes des colonnes numériques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Regroupement par sous-groupe d'aliment \n",
    "clustMax = ens_df[indMax].groupby('Sous-groupe d aliment').mean(numeric_only=True)\n",
    "clustMin = ens_df[indMin].groupby('Sous-groupe d aliment').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " clustMax.head(5).sort_values('Total.14')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(clustMax, indMax, \"Total.14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustMin.head(5).sort_values('Total.14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrage du dataframe pour les codes AGB correspondants :\n",
    "Afin d'obtenir des informations spécifiques sur les aliments et de vérifier leur impact sur le changement climatique, nous effectuons un filtrage du dataframe \"data_synthese\" en utilisant la liste des codes AGB du cluster présentant le taux le plus élevé d'écotoxicité. Cette opération nous permet de sélectionner les données pertinentes liées aux aliments concernés et d'analyser leur impact sur le changement climatique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "liste_codes = ens_df[indMax][\"Code AGB\"].tolist()\n",
    "\n",
    "# Filtrer le DataFrame\n",
    "df_filtrer = data_synthese[data_synthese[\"Code AGB\"].isin(liste_codes)]\n",
    "\n",
    "df_filtrer[[\"Code AGB\",\"Sous-groupe d'aliment\",\"classe\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ev.classe_majoritaire(np.array(df_filtrer[\"classe\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation des résultats obtenus :\n",
    "<br>\n",
    "À travers notre étude sur l'écotoxicité des écosystèmes aquatiques d'eau douce liée aux différentes étapes de production et de distribution des aliments, nous avons obtenu des résultats significatifs. L'analyse des clusters formés nous permet de tirer des conclusions importantes concernant l'impact environnemental des sous-groupes d'aliments étudiés.\n",
    "<br><br>\n",
    "Sur la base des données recueillies, nous constatons que parmi tous les aliments classés en clusters, un cluster en particulier présente un niveau d'écotoxicité préoccupant. Ce cluster, qui représente 90% de l'ensemble des aliments classés, est principalement composé de 27.1% de poissons crus, 40.1% de poissons cuits et 32.8% de fruits.\n",
    "<br><br>\n",
    "Cependant, il est important de noter que bien que ces aliments soient écotoxiques, leur impact sur le changement climatique est très faible. Cette observation souligne la complexité des interactions environnementales et met en évidence la nécessité d'une évaluation globale des différents aspects environnementaux liés à la production alimentaire.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir analysé l'écotoxicité des écosystèmes aquatiques d'eau douce liée à la production alimentaire, notre étude se penche désormais sur d'autres aspects environnementaux importants. Nous nous intéressons spécifiquement à l'évaluation de quatre paramètres clés : le rapport **Pt/kg de produit,** (quantité de polluants ou substances toxiques présents par kilogramme de produit); les **m3 de privation d'eau/kg de produit** (consommation d'eau douce nécessaire pour produire un kilogramme de produit); les **MJ/kg de produit** (quantité d'énergie en mégajoules nécessaire pour produire un kilogramme de produit); et les **kg Sb eq/kg de produit** ( mesure de l'impact environnemental potentiel du produit en termes d'émission de substances toxiques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour réaliser l'étude sur ces aspects, nous avons suivi presque les mêmes demarches que precedemment en utilisant cette fois ci le dataframe dat_ingredients :\n",
    "\n",
    "1. **Normalisation des données**  \n",
    "\n",
    "2. **Application de l'algorithme des K-moyennes**\n",
    "\n",
    "3. **Analyse des résultats** \n",
    "\n",
    "4. **Extraction des données pertinentes** \n",
    "\n",
    "5. **Visualisation des résultats** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supprimer les lignes en double basées sur la colonne 'Ciqual AGB' et garder uniquement la dernière occurrence\n",
    "df_ingredients = data_ingredients.drop_duplicates(subset=['Ciqual AGB'], keep='last')\n",
    "\n",
    "# Réinitialiser l'index du DataFrame\n",
    "df_ingredients = df_ingredients.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Pt/kg de produit, (quantité de polluants ou substances toxiques présents par kilogramme de produit)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_pt_kg = clust.normalisation(df_ingredients[[\"Pt/kg de produit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_norm_pt_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centres_pt_kg, affectation_pt_kg = clust.kmoyennes(6, df_norm_pt_kg,0.0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clust.affiche_resultat(df_norm_pt_kg, centres_pt_kg, affectation_pt_kg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_df_pt_kg, labels_pt_kg, valeurs_pt_kg, indMax_pt_kg,_ = df_clusters(df_ingredients, affectation_pt_kg, \"Pt/kg de produit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt_pie(\"Répartition des clusters en fonction de Pt/kg de produit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement par sous-groupe d'aliment et somme des colonnes numériques\n",
    "clustMax_pt_kg = ens_df_pt_kg[indMax_pt_kg].groupby(\"Sous-groupe d'aliment\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Affichage du dataframe qui contient le taux le plus élévé\n",
    "clustMax_pt_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(clustMax_pt_kg, indMax_pt_kg, \"Pt/kg de produit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. m3 depriv./kg de produit  (consommation d'eau douce nécessaire pour produire un kilogramme de produit)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_m3_depriv = clust.normalisation(df_ingredients[[\"m3 depriv./kg de produit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_norm_m3_depriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centresm3_depriv, affectationm3_depriv = clust.kmoyennes(6, df_norm_m3_depriv,0.0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clust.affiche_resultat(df_norm_m3_depriv, centres_m3_depriv, affectation_m3_depriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_df_m3_depriv, labels_m3_depriv, valeurs_m3_depriv, indMax_m3_depriv,_ = df_clusters(df_ingredients,affectationm3_depriv,\"m3 depriv./kg de produit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_pie(\"Répartition des clusters en fonction de m3 depriv./kg de produit\", valeurs_m3_depriv, labels_m3_depriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement par sous-groupe d'aliment et somme des colonnes numériques\n",
    "clustMax_m3_depriv = ens_df_m3_depriv[indMax_m3_depriv].groupby(\"Sous-groupe d'aliment\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clustMax_m3_depriv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(clustMax_m3_depriv, indMax_m3_depriv, \"m3 depriv./kg de produit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. MJ/kg de produit (quantité d'énergie en mégajoules nécessaire pour produire un kilogramme de produit)\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_MJ_kg = clust.normalisation(df_ingredients[[\"MJ/kg de produit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centres_MJ_kg, affectation_MJ_kg = clust.kmoyennes(5, df_norm_MJ_kg,0.0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_df_MJ_kg, labels_MJ_kg, valeurs_MJ_kg, indMax_MJ_kg,_ = df_clusters(df_ingredients,affectation_MJ_kg,\"MJ/kg de produit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_pie(\"Répartition des clusters en fonction de MJ/kg de produit\", valeurs_MJ_kg, labels_MJ_kg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement par sous-groupe d'aliment et somme des colonnes numériques\n",
    "clustMax_MJ_kg = ens_df_MJ_kg[indMax_MJ_kg].groupby(\"Sous-groupe d'aliment\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustMax_MJ_kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(clustMax_MJ_kg, indMax_MJ_kg, \"MJ/kg de produit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d. kg Sb eq/kg de produit ( mesure de l'impact environnemental potentiel du produit en termes d'émission de substances toxiques)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm_Sb = clust.normalisation(df_ingredients[[\"kg Sb eq/kg de produit\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centres_Sb, affectation_Sb = clust.kmoyennes(6, df_norm_Sb,0.0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clust.affiche_resultat(df_norm_Sb, centres_Sb, affectation_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_df_Sb, labels_Sb, valeurs_Sb, indMax_Sb,_ = df_clusters(df_ingredients,affectation_Sb,\"kg Sb eq/kg de produit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_pie(\"Répartition des clusters en fonction de kg Sb eq/kg de produit\", valeurs_Sb, labels_Sb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regroupement par sous-groupe d'aliment et somme des colonnes numériques\n",
    "clustMax_Sb = ens_df_Sb[indMax_Sb].groupby(\"Sous-groupe d'aliment\").mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustMax_Sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pie_chart(clustMax_Sb, indMax_Sb, \"kg Sb eq/kg de produit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion :\n",
    "\n",
    "L'analyse des quatre paramètres clés, à savoir le rapport Pt/kg de produit, les m3 de privation d'eau/kg de produit, les MJ/kg de produit et les kg Sb eq/kg de produit, nous a permis de mieux comprendre l'impact environnemental de différents sous-groupes d'aliments. Voici les principales conclusions que nous avons pu tirer de cette analyse :\n",
    "\n",
    "L'étude sur le rapport Pt/kg de produit a révélé que la charcuterie présente le taux le plus élevé parmi tous les sous-groupes d'aliments avec une moyenne de 6678.386241 Pt/kg.\n",
    "\n",
    "En ce qui concerne les m3 de privation d'eau/kg de produit, notre étude a identifié plusieurs sous-groupes d'aliments, tels que les confitures, les céréales de petit-déjeuner, les gâteaux et pâtisseries, les laits et boissons infantiles, les pains et viennoiseries, les produits laitiers frais et assimilés, ainsi que les pâtes, riz et céréales, qui ont une consommation d'eau plus élevée.\n",
    "\n",
    "L'analyse des MJ/kg de produit a révélé que les aides culinaires présentent le taux le plus élevé. Cela signifie que la production d'aides culinaires nécessite une quantité importante d'énergie, ce qui contribue à l'empreinte carbone globale des aliments.\n",
    "\n",
    "Enfin, l'étude des kg Sb eq/kg de produit a mis en évidence les soupes et la charcuterie comme ayant des taux plus élevés. Cela suggère que ces aliments ont un impact environnemental plus important en termes de pollution aux substances toxiques.\n",
    "\n",
    "`La charcuterie se démarque dans deux études clés portant sur le rapport Pt/kg de produit et le kg Sb eq/kg de produit, révélant son impact environnemental préoccupant. En termes de rapport Pt/kg de produit, la charcuterie affiche le taux le plus élevé parmi les sous-groupes d'aliments étudiés, soulignant sa contribution significative à la production de polluants toxiques. De plus, dans l'étude du kg Sb eq/kg de produit, la charcuterie se distingue également avec un taux supérieur aux autres aliments.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
